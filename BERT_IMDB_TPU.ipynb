{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_IMDB_TPU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felipefreitas93/Colab_Notebooks/blob/master/BERT_IMDB_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meO7ZaISZfZ1",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhdjgZWAZ60C",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHQH4OCHZ9bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "FRAC=0.4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkTLZ3I4_7c_",
        "colab_type": "text"
      },
      "source": [
        "# BERT End to End (Fine-tuning + Predicting) in 5 minutes with Cloud TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wtjs1QDb3DX",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "\n",
        "**BERT**, or **B**idirectional **E**mbedding **R**epresentations from **T**ransformers, is a new method of pre-training language representations which obtains state-of-the-art results on a wide array of Natural Language Processing (NLP) tasks. The academic paper can be found here: https://arxiv.org/abs/1810.04805.\n",
        "\n",
        "This Colab demonstates using a free Colab Cloud TPU to fine-tune sentence and sentence-pair classification tasks built on top of pretrained BERT models and \n",
        "run predictions on tuned model. The colab demonsrates loading pretrained BERT models from both [TF Hub](https://www.tensorflow.org/hub) and checkpoints.\n",
        "\n",
        "**Note:**  You will need a GCP (Google Compute Engine) account and a GCS (Google Cloud \n",
        "Storage) bucket for this Colab to run.\n",
        "\n",
        "Please follow the [Google Cloud TPU quickstart](https://cloud.google.com/tpu/docs/quickstart) for how to create GCP account and GCS bucket. You have [$300 free credit](https://cloud.google.com/free/) to get started with any GCP product. You can learn more about Cloud TPU at https://cloud.google.com/tpu/docs.\n",
        "\n",
        "This notebook is hosted on GitHub. To view it in its original repository, after opening the notebook, select **File > View on GitHub**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjiKRZ_faLRy",
        "colab_type": "text"
      },
      "source": [
        "## Learning objectives\n",
        "\n",
        "In this notebook, you will learn how to train and evaluate a BERT model using TPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld-JXlueIuPH",
        "colab_type": "text"
      },
      "source": [
        "## Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POkof5uHaQ_c",
        "colab_type": "text"
      },
      "source": [
        "<h3><a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>  &nbsp;&nbsp;Train on TPU</h3>\n",
        "\n",
        "   1. Create a Cloud Storage bucket for your TensorBoard logs at http://console.cloud.google.com/storage and fill in the BUCKET parameter in the \"Parameters\" section below.\n",
        " \n",
        "   1. On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n",
        "   1. Click Runtime again and select **Runtime > Run All** (Watch out: the \"Colab-only auth for this notebook and the TPU\" cell requires user input). You can also run the cells manually with Shift-ENTER."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdMmwCJFaT8F",
        "colab_type": "text"
      },
      "source": [
        "### Set up your TPU environment\n",
        "\n",
        "In this section, you perform the following tasks:\n",
        "\n",
        "*   Set up a Colab TPU running environment\n",
        "*   Verify that you are connected to a TPU device\n",
        "*   Upload your credentials to TPU to access your GCS bucket."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "191zq3ZErihP",
        "colab_type": "code",
        "outputId": "9ebf421d-a9ff-4292-8c05-c421652eec1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.21.210.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0723 00:22:48.384666 140545505412992 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 11380461516443156851),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 6082199953963925466),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 7064281867338314167),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 8259775504436566504),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 16713438994420825002),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7712017781076223307),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 14784090319552440623),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 2666544502027665090),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 4752473757136087791),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 5938608180582651519),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 10853663492479889571)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUBP35oCDmbF",
        "colab_type": "text"
      },
      "source": [
        "### Prepare and import BERT modules\n",
        "​\n",
        "With your environment configured, you can now prepare and import the BERT modules. The following step clones the source code from GitHub and import the modules from the source. Alternatively, you can install BERT using pip (!pip install bert-tensorflow)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wzwke0sxS6W",
        "colab_type": "code",
        "outputId": "192fa476-cf92-41e8-9a67-9e1bef970a14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "import sys\n",
        "\n",
        "!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n",
        "if not 'bert_repo' in sys.path:\n",
        "  sys.path += ['bert_repo']\n",
        "\n",
        "# import python modules defined by BERT\n",
        "import modeling\n",
        "import optimization\n",
        "import run_classifier\n",
        "import run_classifier_with_tfhub\n",
        "import tokenization\n",
        "\n",
        "# import tfhub \n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert_repo'...\n",
            "remote: Enumerating objects: 333, done.\u001b[K\n",
            "remote: Total 333 (delta 0), reused 0 (delta 0), pack-reused 333\u001b[K\n",
            "Receiving objects: 100% (333/333), 277.61 KiB | 3.75 MiB/s, done.\n",
            "Resolving deltas: 100% (183/183), done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0723 00:22:53.018074 140545505412992 deprecation_wrapper.py:119] From bert_repo/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRu1aKO1D7-Z",
        "colab_type": "text"
      },
      "source": [
        "### Prepare for training\n",
        "\n",
        "This next section of code performs the following tasks:\n",
        "\n",
        "*  Specify task and download training data.\n",
        "*  Specify BERT pretrained model\n",
        "*  Specify GS bucket, create output directory for model checkpoints and eval results.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYkaAlJNfhul",
        "colab_type": "code",
        "outputId": "af44602d-6e4b-4a59-8a1b-660cdd3a0316",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "TASK = 'CoLA' #@param {type:\"string\"}\n",
        "assert TASK in ('MRPC', 'CoLA'), 'Only (MRPC, CoLA) are demonstrated here.'\n",
        "\n",
        "# Download glue data.\n",
        "! test -d download_glue_repo || git clone https://gist.github.com/60c2bdb54d156a41194446737ce03e2e.git download_glue_repo\n",
        "!python download_glue_repo/download_glue_data.py --data_dir='glue_data' --tasks=$TASK\n",
        "\n",
        "TASK_DATA_DIR = 'glue_data/' + TASK\n",
        "print('***** Task data directory: {} *****'.format(TASK_DATA_DIR))\n",
        "!ls $TASK_DATA_DIR\n",
        "\n",
        "BUCKET = 'deep_learning_bucket_mestrado' #@param {type:\"string\"}\n",
        "assert BUCKET, 'Must specify an existing GCS bucket name'\n",
        "OUTPUT_DIR = 'gs://{}/bert-tfhub/models/{}'.format(BUCKET, TASK)\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "\n",
        "# Available pretrained model checkpoints:\n",
        "#   backup original model = uncased_L-12_H-768_A-12\n",
        "#   uncased_L-12_H-768_A-12: uncased BERT base model\n",
        "#   uncased_L-24_H-1024_A-16: uncased BERT large model\n",
        "#   cased_L-12_H-768_A-12: cased BERT large model\n",
        "BERT_MODEL = 'uncased_L-24_H-1024_A-16' #@param {type:\"string\"}\n",
        "BERT_MODEL_HUB = 'https://tfhub.dev/google/bert_' + BERT_MODEL + '/1'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'download_glue_repo'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Total 21 (delta 0), reused 0 (delta 0), pack-reused 21\u001b[K\n",
            "Unpacking objects:   4% (1/21)   \rUnpacking objects:   9% (2/21)   \rUnpacking objects:  14% (3/21)   \rUnpacking objects:  19% (4/21)   \rUnpacking objects:  23% (5/21)   \rUnpacking objects:  28% (6/21)   \rUnpacking objects:  33% (7/21)   \rUnpacking objects:  38% (8/21)   \rUnpacking objects:  42% (9/21)   \rUnpacking objects:  47% (10/21)   \rUnpacking objects:  52% (11/21)   \rUnpacking objects:  57% (12/21)   \rUnpacking objects:  61% (13/21)   \rUnpacking objects:  66% (14/21)   \rUnpacking objects:  71% (15/21)   \rUnpacking objects:  76% (16/21)   \rUnpacking objects:  80% (17/21)   \rUnpacking objects:  85% (18/21)   \rUnpacking objects:  90% (19/21)   \rUnpacking objects:  95% (20/21)   \rUnpacking objects: 100% (21/21)   \rUnpacking objects: 100% (21/21), done.\n",
            "Downloading and extracting CoLA...\n",
            "\tCompleted!\n",
            "***** Task data directory: glue_data/CoLA *****\n",
            "dev.tsv  original  test.tsv  train.tsv\n",
            "***** Model output directory: gs://deep_learning_bucket_mestrado/bert-tfhub/models/CoLA *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hcpfl4N2EdOk",
        "colab_type": "text"
      },
      "source": [
        "Now let's load tokenizer module from TF Hub and play with it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjjhXL6F1GTB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "outputId": "323e09f6-200f-4cd9-c845-13e655a1056b"
      },
      "source": [
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar zxf aclImdb_v1.tar.gz\n",
        "\n",
        "#download imdb dataset\n",
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar zxf aclImdb_v1.tar.gz\n",
        "\n",
        "def get_to_keep(frac):\n",
        "    path_pos = 'aclImdb/train/pos'\n",
        "    path_neg = 'aclImdb/train/neg'\n",
        "    pos_df = pd.DataFrame(os.listdir(path_pos))\n",
        "    to_keep_pos = pos_df.sample(frac=frac, random_state=1)[0].values.tolist()\n",
        "    neg_df = pd.DataFrame(os.listdir(path_neg))\n",
        "    to_keep_neg = neg_df.sample(frac=frac, random_state=1)[0].values.tolist()\n",
        "    for value_pos in os.listdir(path_pos):\n",
        "        if value_pos not in to_keep_pos:\n",
        "            os.remove(os.path.join(path_pos ,value_pos))\n",
        "    for value_neg in os.listdir(path_neg):\n",
        "        if value_neg not in to_keep_neg:\n",
        "            os.remove(os.path.join(path_neg ,value_neg))\n",
        "\n",
        "# Load all files from a directory in a DataFrame.\n",
        "def load_directory_data(directory):\n",
        "    data = {}\n",
        "    data[\"sentence\"] = []\n",
        "    data[\"sentiment\"] = []\n",
        "    for file_path in os.listdir(directory):\n",
        "        with tf.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
        "            data[\"sentence\"].append(f.read())\n",
        "            data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
        "    return pd.DataFrame.from_dict(data)\n",
        "\n",
        "# Merge positive and negative examples, add a polarity column and shuffle.\n",
        "def load_dataset(directory):\n",
        "    pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
        "    neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
        "    pos_df[\"polarity\"] = 1\n",
        "    neg_df[\"polarity\"] = 0\n",
        "    return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Download and process the dataset files.\n",
        "def load_datasets():\n",
        "    train_df = load_dataset(os.path.join(\"aclImdb\", \"train\"))\n",
        "    test_df = load_dataset(os.path.join(\"aclImdb\", \"test\"))\n",
        "\n",
        "    return train_df, test_df\n",
        "  \n",
        "#fraction of the data you want to keep\n",
        "get_to_keep(FRAC)\n",
        "train_full, test_full = load_datasets()\n",
        "train_full['a'] = 'a'\n",
        "train_full['index'] = train_full.index.values\n",
        "df_bert_train = train_full[['index', 'polarity', 'a', 'sentence']]\n",
        "df_bert_train['sentence'] = df_bert_train['sentence'].apply(str.lower)\n",
        "\n",
        "test_full['a'] = 'a'\n",
        "test_full['index'] = test_full.index.values\n",
        "df_bert_test = test_full[['index', 'polarity', 'a', 'sentence']]\n",
        "df_bert_test['sentence'] = df_bert_test['sentence'].apply(str.lower)\n",
        "df_bert_dev = df_bert_test\n",
        "\n",
        "#df_bert_dev = train_full.loc[:10]\n",
        "#df_bert_test =  pd.DataFrame(test_full.index.values, columns=['id'])\n",
        "#df_bert_test['sentence'] = test_full[['sentence']]\n",
        "#df_bert_test['sentence'] = df_bert_test['sentence'].apply(str.lower)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-23 00:23:01--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  26.3MB/s    in 3.1s    \n",
            "\n",
            "2019-07-23 00:23:04 (26.3 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n",
            "--2019-07-23 00:23:13--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz.1’\n",
            "\n",
            "aclImdb_v1.tar.gz.1 100%[===================>]  80.23M  26.6MB/s    in 3.0s    \n",
            "\n",
            "2019-07-23 00:23:16 (26.6 MB/s) - ‘aclImdb_v1.tar.gz.1’ saved [84125825/84125825]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NIJcrpVzrg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf glue_data/CoLA/original"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83L5catz1xdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_bert_train.to_csv('glue_data/CoLA/train.tsv', sep='\\t', index=False, header=False)\n",
        "df_bert_dev.to_csv('glue_data/CoLA/dev.tsv', sep='\\t', index=False, header=False)\n",
        "df_bert_test.to_csv('glue_data/CoLA/test.tsv', sep='\\t', index=False, header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TylDOYd-6AH-",
        "colab_type": "code",
        "outputId": "ed730055-e1c1-4e3c-f16e-a98327a68eeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "tokenizer = run_classifier_with_tfhub.create_tokenizer_from_hub_module(BERT_MODEL_HUB)\n",
        "tokenizer.tokenize(\"This here's an example of using the BERT tokenizer\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0723 00:24:07.773743 140545505412992 deprecation_wrapper.py:119] From bert_repo/run_classifier_with_tfhub.py:151: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0723 00:24:08.469660 140545505412992 deprecation_wrapper.py:119] From bert_repo/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this',\n",
              " 'here',\n",
              " \"'\",\n",
              " 's',\n",
              " 'an',\n",
              " 'example',\n",
              " 'of',\n",
              " 'using',\n",
              " 'the',\n",
              " 'bert',\n",
              " 'token',\n",
              " '##izer']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqQ_LHyzcoYW",
        "colab_type": "text"
      },
      "source": [
        "Also we initilize our hyperprams, prepare the training data and initialize TPU config."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYVYULZiKvUi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d0f01150-a631-430b-db32-76e44ad05097"
      },
      "source": [
        "TRAIN_BATCH_SIZE = 32\n",
        "EVAL_BATCH_SIZE = 32\n",
        "PREDICT_BATCH_SIZE = 8\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 3.0\n",
        "MAX_SEQ_LENGTH = 256\n",
        "# Warmup is a period of time where hte learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 2000\n",
        "SAVE_SUMMARY_STEPS = 500\n",
        "\n",
        "processors = {\n",
        "  \"cola\": run_classifier.ColaProcessor,\n",
        "  \"mnli\": run_classifier.MnliProcessor,\n",
        "  \"mrpc\": run_classifier.MrpcProcessor,\n",
        "}\n",
        "processor = processors[TASK.lower()]()\n",
        "label_list = processor.get_labels()\n",
        "\n",
        "# Compute number of train and warmup steps from batch size\n",
        "train_examples = processor.get_train_examples(TASK_DATA_DIR)\n",
        "num_train_steps = int(len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "# Setup TPU related config\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "NUM_TPU_CORES = 8\n",
        "ITERATIONS_PER_LOOP = 1000\n",
        "\n",
        "def get_run_config(output_dir):\n",
        "  return tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=output_dir,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0723 00:24:08.649438 140545505412992 deprecation_wrapper.py:119] From bert_repo/run_classifier.py:199: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3iFMeqLaSll",
        "colab_type": "text"
      },
      "source": [
        "# Fine-tune and Run Predictions on a pretrained BERT Model from TF Hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXyJRc0OIHEU",
        "colab_type": "text"
      },
      "source": [
        "This section demonstrates fine-tuning from a pre-trained BERT TF Hub module and running predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwcsdbLuIX2I",
        "colab_type": "code",
        "outputId": "578864f8-2d4a-41ec-fd84-924217cbaac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Force TF Hub writes to the GS bucket we provide.\n",
        "os.environ['TFHUB_CACHE_DIR'] = OUTPUT_DIR\n",
        "\n",
        "model_fn = run_classifier_with_tfhub.model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps,\n",
        "  use_tpu=True,\n",
        "  bert_hub_module_handle=BERT_MODEL_HUB\n",
        ")\n",
        "\n",
        "estimator_from_tfhub = tf.contrib.tpu.TPUEstimator(\n",
        "  use_tpu=True,\n",
        "  model_fn=model_fn,\n",
        "  config=get_run_config(OUTPUT_DIR),\n",
        "  train_batch_size=TRAIN_BATCH_SIZE,\n",
        "  eval_batch_size=EVAL_BATCH_SIZE,\n",
        "  predict_batch_size=PREDICT_BATCH_SIZE,\n",
        ")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0723 00:24:09.995680 140545505412992 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fd300abb730>) includes params argument, but params are not passed to Estimator.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGVYj_rlcDhc",
        "colab_type": "text"
      },
      "source": [
        "At this point, you can now fine-tune the model, evaluate it, and run predictions on it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U_c8s2AvhgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model\n",
        "def model_train(estimator):\n",
        "  print('MRPC/CoLA on BERT base model normally takes about 2-3 minutes. Please wait...')\n",
        "  # We'll set sequences to be at most 128 tokens long.\n",
        "  train_features = run_classifier.convert_examples_to_features(\n",
        "      train_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  print('***** Started training at {} *****'.format(datetime.datetime.now()))\n",
        "  print('  Num examples = {}'.format(len(train_examples)))\n",
        "  print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n",
        "  tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
        "  train_input_fn = run_classifier.input_fn_builder(\n",
        "      features=train_features,\n",
        "      seq_length=MAX_SEQ_LENGTH,\n",
        "      is_training=True,\n",
        "      drop_remainder=True)\n",
        "  estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "  print('***** Finished training at {} *****'.format(datetime.datetime.now()))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRhzyk4_WD2n",
        "colab_type": "code",
        "outputId": "e513759b-b0f9-4d25-8795-9b1e0795a459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "model_train(estimator_from_tfhub)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0723 00:24:10.033394 140545505412992 deprecation_wrapper.py:119] From bert_repo/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MRPC/CoLA on BERT base model normally takes about 2-3 minutes. Please wait...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0723 00:25:07.237847 140545505412992 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Started training at 2019-07-23 00:25:07.103535 *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0723 00:26:14.847588 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/input_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:14.849780 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/input_mask) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:14.851554 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/segment_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:14.853778 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/mlm_positions) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:14.862259 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/word_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:14.876877 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/token_type_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:14.886430 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/position_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:14.895187 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:14.899350 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:14.922462 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:14.926580 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:14.936234 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:14.940217 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:14.948500 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:14.953135 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:14.970537 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:14.974538 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:14.986834 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:14.990720 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.001628 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.005378 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.015977 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.019992 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.031048 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.034957 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.047655 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.051581 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.060258 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.066680 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.074661 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.079588 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.097245 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.102257 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.113330 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.118330 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.128759 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.134825 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.146188 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.155713 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.166852 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.172906 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.184555 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.189628 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.197529 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.202314 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.210727 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.216793 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.235369 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.239498 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.252258 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.257459 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.268243 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.273588 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.283546 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.291248 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.300827 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.307731 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.317833 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.323943 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.330750 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.334448 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.346594 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.353535 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.369660 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.377255 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.386926 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.393412 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.402997 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.411394 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.423815 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.427825 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.439472 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.446424 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.458253 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.463895 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.471415 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.475430 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.482627 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.486562 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.504513 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.508717 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.521240 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.527357 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.538552 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.542227 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.552766 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.556858 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.572848 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.579414 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.593698 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.598691 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.605724 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.610901 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.617618 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.621503 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.638733 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.642645 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.654430 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.658244 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.678489 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.682261 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.694058 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.698173 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.708968 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.713764 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.728467 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.732587 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.740034 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.744114 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.751321 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.755316 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.772221 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.776900 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.787762 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.791505 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.806402 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.815440 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.826768 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.832567 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.842862 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.847661 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.862032 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.868432 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.876728 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.882203 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.890548 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.894280 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.916155 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.920173 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.933167 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.937212 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.950852 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.954946 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.965491 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.969779 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.980848 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.984656 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:15.996910 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.000778 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.013033 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.020071 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.027829 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.031877 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.050135 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.054262 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.066344 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.070473 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.081249 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.085192 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.096156 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.100248 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.111434 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.115564 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.128789 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.132717 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.141915 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.145783 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.153975 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.157806 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.174753 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.178668 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.189460 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.193178 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.204168 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.208008 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.219007 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.222995 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.234577 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.238506 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.250709 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.258607 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.267070 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.273488 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.281576 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.289380 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.308324 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.314636 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.325598 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.331420 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.341740 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.347505 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.359736 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.365313 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.376652 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.380775 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.398240 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.402166 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.411750 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.415848 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.425349 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.429558 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.448150 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.452293 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.463451 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.467422 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.480004 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.484294 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.495854 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.499636 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.510543 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.514562 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.529623 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.533655 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.541889 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.546667 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.555419 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.559822 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.576607 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.580452 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.593560 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.597400 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.609183 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.613451 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.625345 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.629077 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.640465 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.644580 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.657562 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.661591 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.671288 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.674971 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.683366 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.687318 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.704885 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.709115 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.721652 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.725699 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.736701 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.740833 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.751510 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.755429 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.766523 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.770345 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.783382 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.787232 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.795881 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.799746 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.807806 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.819964 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.840499 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.844632 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.856372 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.860949 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.872038 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.876394 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.886748 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.890598 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.902145 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.906152 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.919539 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.923697 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.930667 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.935275 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.944538 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.949008 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.966335 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.970246 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.982573 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.986422 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:16.998339 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.002655 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.013857 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.017786 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.029687 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.033786 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.047872 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.051916 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.061008 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.069581 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.079118 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.084732 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.102389 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.106991 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.121338 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.126647 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.138078 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.142298 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.154341 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.160249 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.172748 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.176674 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.191191 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.197678 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.206274 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.212995 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.221640 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.227614 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.246527 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.252609 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.265823 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.269868 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.283482 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.287528 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.298125 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.302345 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.313668 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.317611 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.332394 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.336459 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.346200 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.350138 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.358921 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.364474 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.382016 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.385817 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.398445 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.402510 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.415660 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.419642 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.435319 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.440178 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.451150 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.455320 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.468398 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.472162 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.481842 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.486503 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.494216 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.498219 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.517768 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.521958 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.534854 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.541529 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.550165 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.554600 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.564073 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.569689 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.577900 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.582422 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.597236 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.601888 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.608686 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.615253 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.621891 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.628409 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.644798 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.653774 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.663357 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.670413 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.679271 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.685745 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.693995 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.699887 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.709852 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.715853 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.726419 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.731552 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.739162 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.744601 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.750771 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.756494 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.774872 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.779637 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.791646 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.797298 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.808538 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.814470 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.824056 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.830765 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.844630 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.850895 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.862076 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.867817 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.874653 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.881130 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.887311 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.892503 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.910130 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.916113 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.931298 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.935411 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.946308 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.950192 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.961611 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.965589 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.977457 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.981400 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.995819 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:17.999877 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:18.008517 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:18.012356 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:18.019751 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:18.024111 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:18.040679 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:18.044689 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:18.058428 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:18.062541 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:18.074469 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:18.078578 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:18.089869 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:18.095993 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:18.106121 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:18.110225 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:18.158606 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:18.163810 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:18.177175 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:18.182321 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:18.191506 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:18.196962 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:26:18.208039 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/output_bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "W0723 00:26:18.725527 140545505412992 deprecation_wrapper.py:119] From bert_repo/run_classifier_with_tfhub.py:62: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0723 00:26:18.747235 140545505412992 deprecation_wrapper.py:119] From bert_repo/run_classifier_with_tfhub.py:69: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0723 00:26:18.748846 140545505412992 deprecation.py:506] From bert_repo/run_classifier_with_tfhub.py:72: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0723 00:26:18.827178 140545505412992 deprecation_wrapper.py:119] From bert_repo/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0723 00:26:18.830623 140545505412992 deprecation_wrapper.py:119] From bert_repo/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "W0723 00:26:18.846570 140545505412992 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0723 00:26:18.868910 140545505412992 deprecation_wrapper.py:119] From bert_repo/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W0723 00:26:19.260570 140545505412992 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "W0723 00:28:42.418317 140545505412992 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:741: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Finished training at 2019-07-23 00:35:06.246964 *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoXRtSPZvdiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_eval(estimator):\n",
        "  # Eval the model.\n",
        "  eval_examples = processor.get_dev_examples(TASK_DATA_DIR)\n",
        "  eval_features = run_classifier.convert_examples_to_features(\n",
        "      eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  print('***** Started evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "  print('  Num examples = {}'.format(len(eval_examples)))\n",
        "  print('  Batch size = {}'.format(EVAL_BATCH_SIZE))\n",
        "\n",
        "  # Eval will be slightly WRONG on the TPU because it will truncate\n",
        "  # the last batch.\n",
        "  eval_steps = int(len(eval_examples) / EVAL_BATCH_SIZE)\n",
        "  eval_input_fn = run_classifier.input_fn_builder(\n",
        "      features=eval_features,\n",
        "      seq_length=MAX_SEQ_LENGTH,\n",
        "      is_training=False,\n",
        "      drop_remainder=True)\n",
        "  result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
        "  print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "  output_eval_file = os.path.join(OUTPUT_DIR, \"eval_results.txt\")\n",
        "  with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
        "    print(\"***** Eval results *****\")\n",
        "    for key in sorted(result.keys()):\n",
        "      print('  {} = {}'.format(key, str(result[key])))\n",
        "      writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLQehBr4WHjj",
        "colab_type": "code",
        "outputId": "d3e649a9-4076-4db9-dcaf-93440bf5e5c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "model_eval(estimator_from_tfhub)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Started evaluation at 2019-07-23 00:37:22.118592 *****\n",
            "  Num examples = 25000\n",
            "  Batch size = 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0723 00:38:03.221077 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/input_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.223304 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/input_mask) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.225277 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/segment_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.227074 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/mlm_positions) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.235551 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/word_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.250496 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/token_type_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.263152 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/position_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.273205 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.278009 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.298233 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.302215 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.310262 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.317794 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.326127 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.332072 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.347149 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.353824 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.362262 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.368119 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.378918 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.384832 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.395690 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.401483 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.409375 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.414890 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.427583 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.434592 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.442769 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.447368 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.455602 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.460346 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.474858 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.479653 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.487926 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.492574 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.503136 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.507184 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.520462 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.524393 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.532514 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.536784 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.551411 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.555472 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.564219 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.567996 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.580006 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.586604 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.603796 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.607921 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.615966 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.621665 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.630563 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.635197 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.645453 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.650835 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.657554 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.662878 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.673533 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.678390 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.686117 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.691692 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.698481 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.703141 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.722594 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.727195 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.733372 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.738149 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.750310 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.755331 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.773711 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.777625 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.784128 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.788486 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.802159 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.810466 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.820339 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.824342 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.832834 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.836845 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.852203 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.856196 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.862260 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.866516 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.876668 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.880611 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.891016 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.895238 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.903240 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.908692 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.921978 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.927927 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.938639 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.942496 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.951674 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.955626 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.972831 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.977749 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.985688 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:03.991703 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.005113 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.009562 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.024127 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.028690 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.035861 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.043201 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.060350 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.064359 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.072208 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.076820 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.085307 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.090128 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.105615 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.109759 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.118752 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.122655 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.134889 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.138969 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.151615 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.156157 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.163365 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.167365 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.179174 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.183662 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.193466 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.198039 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.205937 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.214220 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.230847 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.234879 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.243562 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.247497 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.258308 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.262602 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.273661 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.277925 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.286749 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.293688 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.306331 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.310617 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.317941 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.327227 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.335563 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.343485 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.359262 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.365622 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.373851 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.379677 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.392244 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.397708 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.409125 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.415814 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.424598 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.429540 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.444527 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.448761 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.457752 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.463608 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.471567 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.476750 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.491327 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.495540 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.502516 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.507644 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.517884 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.522028 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.533266 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.537485 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.545417 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.550147 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.562781 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.567688 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.575776 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.579880 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.587657 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.592325 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.610566 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.614782 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.621850 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.627940 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.638959 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.642978 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.653222 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.657452 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.663959 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.668777 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.683545 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.687540 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.695752 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.699759 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.708604 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.713293 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.728356 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.732655 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.741615 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.745649 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.756447 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.760520 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.771964 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.775902 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.785140 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.789826 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.801810 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.805813 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.814952 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.821542 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.829585 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.833235 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.848707 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.852655 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.860580 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.865408 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.875278 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.879266 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.889616 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.893570 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.902232 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.906047 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.918422 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.922149 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.930170 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.934502 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.941879 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.946580 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.963096 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.967051 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.975627 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.979596 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.990802 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:04.994977 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.011184 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.015348 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.023531 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.029150 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.042524 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.046456 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.054592 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.058918 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.071069 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.079027 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.094772 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.099122 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.108673 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.112757 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.125188 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.131467 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.144041 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.147949 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.155538 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.161329 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.173116 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.176966 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.185893 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.189711 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.198478 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.202531 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.219590 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.225447 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.233104 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.237207 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.248443 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.252467 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.263358 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.268570 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.274905 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.280829 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.298051 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.302611 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.311171 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.315280 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.322953 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.326889 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.342471 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.349344 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.357599 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.363502 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.374748 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.378463 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.392251 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.396150 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.404838 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.409940 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.421822 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.425899 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.433748 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.445643 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.453552 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.459134 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.474380 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.480691 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.487261 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.493345 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.501934 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.508151 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.518147 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.525184 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.531505 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.536930 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.548537 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.552482 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.561713 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.567124 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.573549 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.578646 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.592448 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.597878 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.605182 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.611994 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.625649 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.630151 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.640098 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.644152 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.652388 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.656428 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.669507 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.673377 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.680212 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.684759 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.694295 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.698669 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.718410 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.722649 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.730681 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.739202 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.750113 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.753989 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.765209 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.769305 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.777625 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.781677 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.794200 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.798351 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.807893 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.812270 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.822714 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.826881 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.842417 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.846343 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.853780 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.860958 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.871479 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.875336 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.886272 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.890511 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.897658 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.905133 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.917635 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.921754 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.931001 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.935235 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.942949 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.946933 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.962477 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.966480 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.976430 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.980489 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.991477 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:05.995598 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.006975 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.011190 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.018642 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.024160 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.041150 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.045845 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.053512 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.057492 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.065268 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.069033 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.083854 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.087988 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.096055 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.100669 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.111078 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.115606 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.126133 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.130249 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.138831 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.143537 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.155858 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.160709 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.169318 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.174031 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.182528 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.187295 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.202338 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.206336 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.216055 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.220154 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.232106 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.236761 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.250154 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.254779 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.262410 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.269969 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.320033 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.326151 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.342325 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.346744 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.357331 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.361731 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0723 00:38:06.374346 140545505412992 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/output_bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "W0723 00:38:07.680136 140545505412992 deprecation_wrapper.py:119] From bert_repo/run_classifier_with_tfhub.py:122: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
            "\n",
            "W0723 00:38:07.705812 140545505412992 deprecation_wrapper.py:119] From bert_repo/run_classifier_with_tfhub.py:123: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "W0723 00:38:09.768458 140545505412992 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Finished evaluation at 2019-07-23 00:39:56.558578 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.9228553\n",
            "  eval_loss = 0.457612\n",
            "  global_step = 937\n",
            "  loss = 0.4937939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHjWhqAodM8a",
        "colab_type": "text"
      },
      "source": [
        "## What's next\n",
        "\n",
        "* Learn about [Cloud TPUs](https://cloud.google.com/tpu/docs) that Google designed and optimized specifically to speed up and scale up ML workloads for training and inference and to enable ML engineers and researchers to iterate more quickly.\n",
        "* Explore the range of [Cloud TPU tutorials and Colabs](https://cloud.google.com/tpu/docs/tutorials) to find other examples that can be used when implementing your ML project.\n",
        "\n",
        "On Google Cloud Platform, in addition to GPUs and TPUs available on pre-configured [deep learning VMs](https://cloud.google.com/deep-learning-vm/),  you will find [AutoML](https://cloud.google.com/automl/)*(beta)* for training custom models without writing code and [Cloud ML Engine](https://cloud.google.com/ml-engine/docs/) which will allows you to run parallel trainings and hyperparameter tuning of your custom models on powerful distributed hardware.\n"
      ]
    }
  ]
}